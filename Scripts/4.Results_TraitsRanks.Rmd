---
title: "4. Main Results"
output: 
  html_document: 
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Introduction

This script calculates the main results for version 3 of the manuscript. It outputs the figures for the main text and a variety of summary statistics. NB the extended data document is generated in a seperate .rmd file.

```{r message = FALSE}
library(tidyverse)
library(knitr)
library(kableExtra)
library(corrplot)
library(broom)
library(cowplot)
library(ggrepel)
library(ggVennDiagram)

kableBOX <- function(df, ...){
  df %>%
    kable(...)%>%
    kable_styling() %>%
    scroll_box(width = "100%", height = "600px")%>%
    return()
}

TraitNames = c("TR_BodyLength_mm","TR_QualBS_Numeric" ,
               "TR_Mean_LengthMax",   "TR_adult_body_mass_g",
               "TR_Mean_SeedMass","TR_Max_Height"  )


TidyName <- c("TR_BodyLength_mm"="Marine:  Body Length",
              "TR_QualBS_Numeric" = "Marine: Qualitative Body Size" ,
              "TR_Mean_LengthMax"= "Fish: Maximum Length", 
              "TR_adult_body_mass_g"= "Amniotes:Adult body mass",
              "TR_Mean_SeedMass"="Plants: Seed Mass",
              "TR_Max_Height"="Plants: Maximum Height"  )
```

# Prepping data

```{r message = FALSE}
read_csv('../TraitTables/bt_names_all_traits.csv' ) %>%
  rowwise %>% 
  mutate( HasTraits =   !all(is.na(TR_BodyLength_mm),
                             is.na(TR_QualitativeBodySize),
                             is.na(TR_Mean_LengthMax),
                             is.na(TR_adult_body_mass_g), 
                             is.na(TR_Mean_SeedMass ),
                             is.na(TR_Max_Height ))) %>%
  ungroup()-> CompleteTraitTable

bt_grid_collate_filter <-  read_csv('../BT_Tables/bt_grid_collate_filter_tidy.csv',
                                    col_types = cols(
                                      STUDY_ID_CELL = col_character(),
                                      STUDY_ID = col_double(),
                                      YEAR = col_double(),
                                      CrossCellAbundance = col_double(),
                                      CrossCellBiomass = col_double(),
                                      ABUNDANCE_TYPE = col_character(),
                                      BIOMASS_TYPE = col_character(),
                                      TidyBTName = col_character(),
                                      canonicalName = col_character(),
                                      rank = col_character(),
                                      kingdom = col_character())) 

bt_meta <- read_csv("../BT_Tables/BioTIMEMetadata_02_04_2018.csv")


bt_grid_collate_filter %>%
  left_join(CompleteTraitTable, 
            by = c('TidyBTName','canonicalName','rank','kingdom')) -> bt_with_traits



## Set qualitative levels in order as a factor, then convert to a numeric
bt_with_traits$TR_QualitativeBodySize <- factor(bt_with_traits$TR_QualitativeBodySize ,
                                                levels = c(  "<0.2 mm"  ,  "0.2 - 2.0 mm", "2.0 - 200 mm",    ">200 mm"     ))

bt_with_traits$TR_QualBS_Numeric <- as.numeric(bt_with_traits$TR_QualitativeBodySize) 


```


### Determine trait-data completeness for each assemblage 

Assessing the completeness of data for each trait for each assemblage to determine what was usable.  

```{r message = FALSE}
bt_with_traits %>% 
  group_by(STUDY_ID_CELL) %>%
  summarise(across(  starts_with('TR_'),    ~ mean(!is.na(.x)),
                     .names =  "Comp_{.col}"))%>%
  mutate( Best_Completeness = pmax(Comp_TR_BodyLength_mm,Comp_TR_QualitativeBodySize,
                                   Comp_TR_Mean_LengthMax, Comp_TR_adult_body_mass_g,
                                   Comp_TR_Mean_SeedMass, Comp_TR_Max_Height)) %>%
  ungroup()-> StudyCell_level_TC

## Where there is only a single level of qualitative size, set 'completeness' to zero, as there is no meaningful information to be used

bt_with_traits %>%
  group_by(STUDY_ID_CELL) %>%
  filter(!is.na(TR_QualitativeBodySize) ) %>%
  summarise( Distinct_QualSize = n_distinct( TR_QualitativeBodySize)) -> Distinct_QualSize


StudyCell_level_TC %>%
  left_join(Distinct_QualSize, by = "STUDY_ID_CELL") %>%
  mutate( Comp_TR_QualitativeBodySize  = ifelse( is.na(Distinct_QualSize) | Distinct_QualSize==1,
                                                 0, Comp_TR_QualitativeBodySize   )) -> StudyCell_level_TC

```

### Determining which data type (abundance or biomass) to use for each assemblage

BioTIME includes a mixture of abundance and biomass data. Only one category was used for each study. Since count data is the most frequent, it was prioritised wen both categories of data were present. Presence/Absence data (28 studies) is not used.  

```{r}
bt_meta %>%
  count(ABUNDANCE_TYPE , BIOMASS_TYPE ) %>%
  kable()
```


```{r}
## Abundance data
StudyCell_level_TC %>%
  separate(STUDY_ID_CELL , into = c('STUDY_ID', 'Cell' ), remove = FALSE, convert = TRUE) %>%
  left_join(bt_meta, by = "STUDY_ID") %>%
  filter( Best_Completeness >0.4) %>%
  filter( ABUNDANCE_TYPE    %in% c('Count', 'Density', 'MeanCount' ))%>%
  mutate( DATA_TYPE_TO_USE = 'Abundance') -> StudyCells_Filt_Abund

## Biomass data

StudyCell_level_TC %>%
  separate(STUDY_ID_CELL , into = c('STUDY_ID', 'Cell' ), remove = FALSE, convert = TRUE) %>%
  left_join(bt_meta, by = "STUDY_ID") %>%
  filter( Best_Completeness >0.4) %>%
  filter(is.na(ABUNDANCE_TYPE) ) %>%
  mutate( DATA_TYPE_TO_USE = 'Biomass') -> StudyCells_Filt_BIOMASS


StudyCells_Filt <-  bind_rows(StudyCells_Filt_Abund, StudyCells_Filt_BIOMASS)

### (This is a df where each row provides details about a particular assemblage)

```

# Finding correlation between traits and community shifts

```{r}
source( 'FitThreeApproaches.R')
```

This function computes three measures of the population trends within each assemblage. 

1)fit through Ranks, 2) Fit through sqrt() then scaled 3) fit through divided by mean

```{r}
### Example:
Find_all_fits_splLvl(StudyCell = '316_442925',
                     all_df = bt_with_traits,trait = 'TR_adult_body_mass_g', 
                     response = 'Abundance' ) -> test

```

## `Run over all' function 

```{r}
RunOverAll <- function( FUNC, CompletenessCutoff = 0.4, all_df, StudyCells_Filt_BOTH , ...){
  ## function to apply an assessor to all traits 
  ## takes StudyCells_Filt_BOTH from env.
  
  WhichStudys<-filter(StudyCells_Filt_BOTH, Comp_TR_BodyLength_mm >CompletenessCutoff)
  BodyLength_mm<- map2_df(WhichStudys$STUDY_ID_CELL, WhichStudys$DATA_TYPE_TO_USE ,   FUNC, all_df = all_df, trait =  'TR_BodyLength_mm', ...)
  
  WhichStudys<-filter(StudyCells_Filt_BOTH, Comp_TR_QualitativeBodySize >CompletenessCutoff)
  QualitativeBodySize<- map2_df(WhichStudys$STUDY_ID_CELL, WhichStudys$DATA_TYPE_TO_USE ,   FUNC, all_df = all_df, trait =  'TR_QualBS_Numeric', ...)
  
  WhichStudys<-filter(StudyCells_Filt_BOTH, Comp_TR_Mean_LengthMax >CompletenessCutoff)
  Mean_LengthMax<- map2_df(WhichStudys$STUDY_ID_CELL, WhichStudys$DATA_TYPE_TO_USE ,   FUNC, all_df = all_df, trait =  'TR_Mean_LengthMax', ...)
  
  WhichStudys<-filter(StudyCells_Filt_BOTH, Comp_TR_adult_body_mass_g >CompletenessCutoff)
  adult_body_mass_g <- map2_df(WhichStudys$STUDY_ID_CELL, WhichStudys$DATA_TYPE_TO_USE ,   FUNC, all_df = all_df, trait =  'TR_adult_body_mass_g', ...)
  
  WhichStudys<-filter(StudyCells_Filt_BOTH, Comp_TR_Mean_SeedMass >CompletenessCutoff)
  Mean_SeedMass <- map2_df(WhichStudys$STUDY_ID_CELL, WhichStudys$DATA_TYPE_TO_USE ,   FUNC, all_df = all_df, trait =  'TR_Mean_SeedMass', ...)
  
  WhichStudys<-filter(StudyCells_Filt_BOTH, Comp_TR_Max_Height >CompletenessCutoff)
  Max_Height <- map2_df(WhichStudys$STUDY_ID_CELL, WhichStudys$DATA_TYPE_TO_USE ,   FUNC, all_df = all_df, trait =  'TR_Max_Height', ...)
  
  ##################
  return( bind_rows(BodyLength_mm, QualitativeBodySize, Mean_LengthMax,
                    adult_body_mass_g, Mean_SeedMass,  Max_Height ))
}

```


```{r eval = FALSE}
### Running over all studies that have a completeness cutoff of 0.4
AllThree_All<-RunOverAll(Find_all_fits_splLvl,
                         CompletenessCutoff = 0.4, 
                         all_df =   bt_with_traits, 
                         StudyCells_Filt_BOTH =StudyCells_Filt)

write_csv( AllThree_All, '../Results/AllThree_All.csv')
```

## Further filtering 

Identifying assemblages with very few species per sample and removing them. This largely removes assemblages from irregularly visited opportunistic data 

```{r message = FALSE}
AllThree_All <- read_csv('../Results/AllThree_All.csv' )

## 1) Only keep those assemblages where >80% of Years  have at least 5 species 

bt_with_traits %>%
  group_by(STUDY_ID_CELL, YEAR) %>%
  summarise(SpPerYear = n_distinct(TidyBTName)) %>%
  summarise( EnoughSpInYear =  mean(SpPerYear >5 )>= 0.8 ) ->EnoughSpInYear



## 2) Only include those species where it is seen in at over half of the time samples. 

bt_with_traits %>%
  group_by(STUDY_ID_CELL) %>%
  summarise(NYears = n_distinct(YEAR))->N_Year

AllThree_All %>%
  left_join(EnoughSpInYear, by = "STUDY_ID_CELL") %>%
  left_join(N_Year, by = "STUDY_ID_CELL") %>% 
  filter( EnoughSpInYear  ,
          N_times_observed >  NYears/2      ) -> AllThree_All_cut1

### 3) Make sure all assemblages have at least 5 species with trait data 

AllThree_All_cut1 %>%
  group_by(STUDY_ID_CELL, trait) %>%
  filter(!is.na(trait_value)) %>%
  summarise(NSP_traitdata = n_distinct( TidyBTName)) %>%
  right_join(AllThree_All_cut1, by = c("STUDY_ID_CELL", "trait")) %>%
  filter(NSP_traitdata >=5) -> AllThree_All_cut2



### 4) Setting essentially flat slopes to zero. 

AllThree_All_cut2 %>%
  mutate(D19_slope    = ifelse( abs(D19_slope )< 0.00001, 0, D19_slope) , 
         Elas_slope = ifelse( abs(D19_slope )< 0.00001, 0, Elas_slope) ,
         Slope= ifelse( abs(D19_slope )< 0.00001, 0, Slope)  ) -> AllThree_All_cut3



### 5) Studies where the above cutting procedures lead to use of less than 1% of the original number of cells  also cut 
## not a good idea to look at a tiny snapshot of 'lucky' cells 

bt_with_traits %>%
  group_by(STUDY_ID)  %>%
  summarise(  N_Cell_Orig = n_distinct(STUDY_ID_CELL) ) -> N_Cell_Orig

AllThree_All_cut3 %>%
  separate(STUDY_ID_CELL , into = c('STUDY_ID', 'Cell' ), remove = FALSE, convert = TRUE) %>%
  distinct(STUDY_ID, STUDY_ID_CELL, trait) %>%
  group_by(STUDY_ID, trait)  %>%
  summarise(  N_Cell = n_distinct(STUDY_ID_CELL) ) %>%
  left_join(N_Cell_Orig, by = "STUDY_ID") %>%
  mutate( FracCellsLeft_PostFilter =  N_Cell/N_Cell_Orig  ) -> StudiesShrunkTooFar

StudiesShrunkTooFar%>% 
  filter( FracCellsLeft_PostFilter< 0.01 ) %>% 
  left_join( select(bt_meta,STUDY_ID, TITLE), by = "STUDY_ID") %>%
  kable(caption = 'Studies removed due to losing over 99% of their cells')


AllThree_All_cut3 %>%
  separate(STUDY_ID_CELL , into = c('STUDY_ID', 'Cell' ), remove = FALSE, convert = TRUE) %>%
  left_join(StudiesShrunkTooFar, by = c("STUDY_ID", "trait")) %>%
  filter( FracCellsLeft_PostFilter> 0.01 )  -> AllThree_All_cut

```

# Analysis

## Checking within study distribution of $\tau$ values

```{r warning = FALSE, message =FALSE}

AllThree_All_cut %>%
  group_by(STUDY_ID_CELL, trait) %>%
  summarise( Beta_kendall_cor= cor(RelTraitRank , Slope, method = 'kendall', use = "na.or.complete")[1],
             Elas_kendall_cor= cor(RelTraitRank , D19_slope , method = 'kendall', use = "na.or.complete")[1],
             D19_kendall_cor = cor(RelTraitRank , Elas_slope , method = 'kendall', use = "na.or.complete")[1]) %>%
  separate(STUDY_ID_CELL   , into= c('STUDY_ID', 'cellID'),  remove = FALSE) %>%
  ungroup() %>%
  gather( 'Metric', 'Tau', 
          Beta_kendall_cor, Elas_kendall_cor, D19_kendall_cor) %>%
  filter( !is.na(Tau)) %>%
  group_by(STUDY_ID, trait,Metric) %>%
  add_count() %>%
  filter(n>1) %>%   ## only bother with those with many assemblages per study
  mutate( log_n = log10(n),
          Study = str_pad(STUDY_ID, width=3, side="left", pad="0")) %>% 
  ggplot( aes(x= Study,  y=Tau, group = STUDY_ID ))+
  geom_boxplot()+
  facet_grid(Metric ~.)+
  ggtitle('Distribution of assemblage-tau values is approximately symmetric in most cases, justifying taking an overall mean' )


AllThree_All_cut %>%
  group_by(STUDY_ID_CELL, trait) %>%
  summarise( Beta_kendall_cor= cor(RelTraitRank , Slope, method = 'kendall', use = "na.or.complete")[1],
             Elas_kendall_cor= cor(RelTraitRank , D19_slope , method = 'kendall', use = "na.or.complete")[1],
             D19_kendall_cor = cor(RelTraitRank , Elas_slope , method = 'kendall', use = "na.or.complete")[1]) %>%
  separate(STUDY_ID_CELL   , into= c('STUDY_ID', 'cellID'),  remove = FALSE) %>%
  group_by(STUDY_ID, trait) %>%
  summarise( Beta_Tau = mean(Beta_kendall_cor, na.rm=TRUE ),
             Elas_Tau = mean(Elas_kendall_cor, na.rm=TRUE ) ,
             D19_Tau = mean(D19_kendall_cor, na.rm=TRUE ) )%>%
  mutate( STUDY_ID = as.numeric(STUDY_ID ))-> Three_Taus


```

## Randomisation tests

To generate a null distribution of expected $\tau$ values given no trait effects, the analysis was repeated 1000 times for each assemblage, where each time the trait values within each trait/study/cell combination were randomised. 

```{r eval = FALSE}
# Each time, randomise trait information (including the absent information) within each assemblage

RandomiseTraitOrderCalcTau <- function( i, df ){
  set.seed(i)
  df %>%
    mutate(RandomisedTraitRank = sample(RelTraitRank , size = n(), replace = FALSE)) %>%
    summarise( Beta_kendall_cor= cor(RandomisedTraitRank , Slope,       method = 'kendall', use = "na.or.complete")[1],
               Elas_kendall_cor= cor(RandomisedTraitRank , D19_slope ,  method = 'kendall', use = "na.or.complete")[1],
               D19_kendall_cor = cor(RandomisedTraitRank , Elas_slope , method = 'kendall', use = "na.or.complete")[1],
               .groups = "keep") %>%
    separate(STUDY_ID_CELL   , into= c('STUDY_ID', 'cellID'),  remove = FALSE) %>%
    group_by(STUDY_ID, trait) %>%
    summarise( Beta_Tau = mean(Beta_kendall_cor, na.rm=TRUE ),
               Elas_Tau = mean(Elas_kendall_cor, na.rm=TRUE ),
               D19_Tau  = mean(D19_kendall_cor , na.rm=TRUE ),
               .groups = "keep" ) %>%
    mutate( STUDY_ID = as.numeric(STUDY_ID ),
            RandomisationID = i)-> Randomised_Taus
  
  cat('.')
  cat(i)
  
  return(Randomised_Taus)
  
}

Randomisations <- map_df( 1:10000,
                          RandomiseTraitOrderCalcTau,
                          df = group_by(AllThree_All_cut, trait, STUDY_ID_CELL ))

write_csv( Randomisations, '../Results/Randomisations10k.csv')
```

```{r warning = FALSE, message =FALSE}
Randomisations <- read_csv( '../Results/Randomisations10k.csv') 
```


### Overall (trait level) Quantile boundaries

```{r warning = FALSE, message =FALSE}

Randomisations %>%
  gather( 'Metric', 'Tau', 
          Beta_Tau, Elas_Tau , D19_Tau) %>%
  filter( !is.na(Tau)) %>%
  group_by(trait,Metric, RandomisationID) %>%
  summarise(    Mean_Tau = mean(Tau)) -> mean_Rando_Taus


mean_Rando_Taus%>%
  group_by(trait,Metric) %>%
  summarise( sd_rand = sd(Mean_Tau),
             Bottom_025= quantile(Mean_Tau, 0.025) ,
             bottomsixth = quantile(Mean_Tau, 1/6),
             Mid = quantile(Mean_Tau, 0.5) ,
             topsixth = quantile(Mean_Tau, 5/6),
             Top_975= quantile(Mean_Tau, 0.975) ) -> Overall_NullDist



Three_Taus %>% 
  gather( 'Metric', 'Tau',   Beta_Tau, Elas_Tau , D19_Tau) %>%
  group_by(trait,Metric) %>%
  summarise(    Mean_Tau = mean(Tau, na.rm=TRUE)) -> mean_Obs_Taus


mean_Obs_Taus %>%
  left_join(Overall_NullDist,
            by = c("trait", "Metric")) %>%
  mutate(significant = ifelse(Mean_Tau  < Bottom_025, 'NEG',
                              ifelse( Mean_Tau > Top_975, 'POS', 
                                      'NO' )))  -> Means_StatsTable

```

### Calculating 'exact' percentile values


```{r}

CalcPValues<-function( sel_trait, obs, mean_Rando_Taus){
  
  
  trait_randos <-   filter( mean_Rando_Taus,trait == sel_trait)
  trait_obs <- arrange(filter(obs, trait == sel_trait), Metric)
  
  Beta_ECDF <- ecdf(filter(trait_randos, Metric == 'Beta_Tau', !is.na(Mean_Tau))$Mean_Tau)
  D19_ECDF <- ecdf(filter(trait_randos, Metric == 'D19_Tau', !is.na(Mean_Tau))$Mean_Tau)
  Elas_ECDF <- ecdf(filter(trait_randos, Metric == 'Elas_Tau', !is.na(Mean_Tau))$Mean_Tau)
  
  return(data.frame( beta_p_value =    2*(1-Beta_ECDF(abs( trait_obs$Mean_Tau[1]  ) )),  
                     D19_p_value =    2*(1-D19_ECDF(abs( trait_obs$Mean_Tau[2]  ) )),  
                     Elas_p_value =    2*(1-Elas_ECDF(abs( trait_obs$Mean_Tau[3]  ) )),
                     trait = sel_trait  ))
}

Means_StatsTable %>%
  left_join(map_df( TraitNames,CalcPValues,
                    obs = ungroup(mean_Obs_Taus), mean_Rando_Taus  ), by = "trait") -> Means_StatsTable

kableBOX(Means_StatsTable)
```




# Study-level significances plots 


### Study_level quantile boundaries:

```{r}
Randomisations %>%
  gather( 'Metric', 'Tau',   Beta_Tau, Elas_Tau , D19_Tau) %>%
  filter( !is.na(Tau)) %>%
  group_by(STUDY_ID ,trait,Metric) %>%
  summarise( sd_rand = sd(Tau),
             Bottom_025= quantile(Tau, 0.025) ,
             bottomsixth = quantile(Tau, 1/6),
             Mid = quantile(Tau, 0.5) ,
             topsixth = quantile(Tau, 5/6),
             Top_975= quantile(Tau, 0.975) ) -> Study_level_NullDist



Three_Taus %>%
  gather( 'Metric', 'Tau',   Beta_Tau, Elas_Tau , D19_Tau) %>%
  left_join(Study_level_NullDist,
            by = c("STUDY_ID", "trait", "Metric")) %>%
  mutate(significant = ifelse(Tau  < Bottom_025, 'NEG',
                              ifelse( Tau > Top_975, 'POS', 
                                      'zInsig' )))   -> Study_level_signifs

Study_level_signifs%>% 
  group_by(Metric) %>%
  count(significant ) %>%
  spread(Metric, n)
```



# Main-text dotplot (Figure 2)

```{r message = FALSE}

MainText_StatsTable  <- filter(Means_StatsTable, Metric == 'D19_Tau'  ) %>%
  select( -beta_p_value , -Elas_p_value ) 

D19_Study_level_signifs<- Study_level_signifs %>% 
  filter( Metric == 'D19_Tau') %>%
  select(STUDY_ID ,trait, significant )

write_csv(Study_level_signifs, '../SIdata/Study_level_signifs.csv')


## Dot-plot histograms

PlotList <- list()

for( i in 1:6){
  
  TRAIT = c("TR_BodyLength_mm","TR_QualBS_Numeric" ,
            "TR_Mean_LengthMax",   "TR_adult_body_mass_g",
            "TR_Mean_SeedMass","TR_Max_Height"  )[i]
  
  name = c("a) Marine:\n  Body length",  "b) Marine:\n  Qualitative body size" ,
           "c) Fish:\n  Maximum length",  "d) Amniotes:\n  Adult body mass",
           "e) Plants:\n  Seed mass",  "f) Plants:\n  Maximum height"  )[i]
  
  
  stats <- filter( MainText_StatsTable , trait ==TRAIT )
  
  print(stats)
  
  stats_dets<-paste0('Cross-Study Mean: ', signif(stats$Mean_Tau , 3),
                     '\np-value: ', signif(stats$D19_p_value,  3))
  
  
  Three_Taus%>%
    filter(trait ==TRAIT) %>% 
    left_join(D19_Study_level_signifs , by = c("STUDY_ID", "trait")) %>% 
    ggplot( aes(D19_Tau))+
    geom_segment( x=0, xend = 0, y = -0.1, yend = 0.6,
                  col = 'grey60' , size = 0.5)+
    geom_dotplot(aes( fill =factor(significant)),
                 binwidth = 0.05, binpositions = 'all',
                 method = 'histodot',
                 origin = 0, stackgroups = TRUE,
                 alpha = 0.7)   + 
    theme(panel.background = element_blank(),
          axis.text.y = element_blank(),
          axis.title.y = element_blank(),
          axis.ticks.y = element_blank())+
    geom_segment( x=stats$Mean_Tau, xend = stats$Mean_Tau, y = -0.05, yend = 0.5,
                  linetype = 'dotted', col = 'red' )+
    
    #   geom_point( y = -0.1,x = stats$Mean_Tau, 
    #              colour = 'blue4', shape = 2)+
    geom_segment(y= -0.04, yend = -0.04,
                 x = stats$Bottom_025,
                 xend =  stats$Top_975 , 
                 colour = 'grey')+
    geom_segment( y= -0.04, yend = -0.04,
                  x = stats$bottomsixth,
                  xend =  stats$topsixth , 
                  size = 2,
                  colour = 'grey25')+
    ggtitle( name, 
             subtitle = stats_dets)+
    scale_fill_manual(  breaks = ,c( 'NEG','POS','Insig'),
                        values = c( 'NEG'='yellow1',
                                    'zInsig'= 'black' ,
                                    'POS' ='blue1') )+
    guides(fill= FALSE)+
    xlab(expression(tau))+
    scale_x_continuous(limits= c(-0.6, 0.6)) +
    scale_y_continuous(limits= c(-0.05, NA)) +
    coord_cartesian(clip = 'off')  -> XX_dots
  XX_dots
  
  PlotList[[i]] <-   XX_dots
}


DotPlots<-cowplot::plot_grid(PlotList[[1]],PlotList[[2]],
                             PlotList[[3]],PlotList[[4]],
                             PlotList[[5]],PlotList[[6]], nrow = 2, scale = 0.95)

DotPlots


ggsave('../Plots/DotPlots2.png', DotPlots,width = 10, height = 6)
ggsave('../Plots/DotPlots2.pdf', DotPlots,width = 10, height = 6)

```

# Concordance between transformations

## Correlations between $\beta$ values 

```{r}
AllThree_All_cut %>%
  select( `Transformation A` = D19_slope,
          `Transformation B` = Elas_slope,
          `Transformation C` = Slope)-> Data4Corr


cor(Data4Corr[,-1],use = 'pairwise') -> CorrTable

Cor1<-  ggplot(Data4Corr, aes( `Transformation A`,  `Transformation B`))+
  geom_point(size = 0.1 ,alpha = 0.3)+
  coord_fixed(xlim = c( -1.5, 1.5), ylim = c( -1.5, 1.5) )+
  ggtitle( paste('Correlation =', signif(CorrTable[1,2],2) ))

Cor2<-  ggplot(Data4Corr, aes( `Transformation A`,  `Transformation C`))+
  geom_point(size = 0.1 ,alpha = 0.3)+
  coord_fixed(xlim = c( -1.5, 1.5), ylim = c( -1.5, 1.5) )+
  ggtitle( paste('Correlation =', signif(CorrTable[1,3],2) ))

Cor3<-  ggplot(Data4Corr, aes( `Transformation B`,  `Transformation C`))+
  geom_point(size = 0.1 ,alpha = 0.3)+
  coord_fixed(xlim = c( -1.5, 1.5), ylim = c( -1.5, 1.5) )+
  ggtitle( paste('Correlation =', signif(CorrTable[2,3],2) ))

CrossTrans_CorInSlopes <-plot_grid( nrow = 1, Cor1, Cor2, Cor3)

CrossTrans_CorInSlopes

ggsave( '../Plots/CrossTrans_CorInSlopes.png', CrossTrans_CorInSlopes, height = 2.5, width = 5, dpi = 300,scale =2  )
ggsave( '../Plots/CrossTrans_CorInSlopes.pdf', CrossTrans_CorInSlopes, height = 2.5, width = 5,scale =2)

```

## Comparison of study-level distribution

```{r}

Means_StatsTable%>%
  mutate( trait= recode(trait , "TR_BodyLength_mm"="Marine:  Body Length",
                        "TR_QualBS_Numeric" = "Marine: Qualitative Body Size" ,
                        "TR_Mean_LengthMax"= "Fish: Maximum Length", 
                        "TR_adult_body_mass_g"= "Amniotes: Adult body mass",
                        "TR_Mean_SeedMass"="Plants: Seed Mass",
                        "TR_Max_Height"="Plants: Maximum Height"  ),
          Metric = recode(Metric, 
                          'Beta_Tau' = "c) Ranking Transformation",
                          'D19_Tau' = "a) Main Text Transformation\n(Cut, sqrt then standardise)",
                          'Elas_Tau' = "b) Alternative Transformation\n(Cut, then divide by mean)" )) -> Means_StatsTable_niceNames


Study_level_signifs %>%
  mutate( trait= recode(trait , "TR_BodyLength_mm"="Marine:  Body Length",
                        "TR_QualBS_Numeric" = "Marine: Qualitative Body Size" ,
                        "TR_Mean_LengthMax"= "Fish: Maximum Length", 
                        "TR_adult_body_mass_g"= "Amniotes: Adult body mass",
                        "TR_Mean_SeedMass"="Plants: Seed Mass",
                        "TR_Max_Height"="Plants: Maximum Height"  ),
          Metric = recode(Metric, 
                          'Beta_Tau' = "c) Ranking Transformation",
                          'D19_Tau' = "a) Main Text Transformation\n(Cut, sqrt then standardise)",
                          'Elas_Tau' = "b) Alternative Transformation\n(Cut, then divide by mean)" )) %>%
  ggplot( )+
  geom_dotplot(aes(Tau, fill =factor(significant)),
               binwidth = 0.05, binpositions = 'all',
               method = 'histodot',
               origin = 0, stackgroups = TRUE,
               alpha = 0.7)   + 
  theme(panel.background = element_blank(),
        axis.text.y = element_blank(),
        axis.title.y = element_blank(),
        axis.ticks.y = element_blank())+
  geom_segment( x=0, xend = 0, y = -0.1, yend = 0.6,
                col = 'grey60' , size = 0.5)+
  geom_segment( data = Means_StatsTable_niceNames,
                aes( x=Mean_Tau, xend = Mean_Tau), y = -0.05, yend = 0.5,
                linetype = 'dotted', col = 'red' )+
  geom_segment( data = Means_StatsTable_niceNames,
                y= -0.04, yend = -0.04,
                aes(x = Bottom_025,xend =  Top_975) , 
                colour = 'grey')+
  geom_segment(  data = Means_StatsTable_niceNames,
                 y= -0.04, yend = -0.04,
                 aes(x = bottomsixth, xend =  topsixth) , 
                 size = 2,
                 colour = 'grey25')+
  scale_fill_manual(  breaks = ,c( 'NEG','POS','Insig'),
                      values = c( 'NEG'='yellow1',
                                  'zInsig'= 'black' ,
                                  'POS' ='blue1') )+
  xlab(expression(tau))+
  guides(fill = FALSE)+
  facet_grid(Metric ~ trait) -> ComparisonDotplots

ComparisonDotplots 

ggsave( '../Plots/ComparisonDotplots.png', ComparisonDotplots, height = 6, width = 10, dpi = 300)
ggsave( '../Plots/ComparisonDotplots.pdf', ComparisonDotplots, height = 6, width = 10)

```


\newpage


## Checks and data wrangling


For the multi-site (ML) studies, results from across cells were averaged to give single study/trait results. Summaries across all cells are shown in the figure. Most of the multi-cell studies look to be relatively normally distributed within each study, justifying taking simple averages. 


# Study level predictors of $\tau$

A suite of potential drivers, 'statistical' and 'ecological' were generated for each trait/study combination. Generally these were the mean value of all constituent cells for the ML studies, rather than grand totals. These were:

- Species richness
- Number of years sampled
- Year Range (i.e time span of the time series) 
- Trait Completeness (fraction of species with trait data)
- Number of cells 
- Range of traits in the community (range of log-trait values, and 95% winsorised log-trait range)

As well as additional values from the original BioTIME metadata

- Study grain ( log10 km^2)
- Latitude (absolute)
- Protected area status (as listed in BioTIME)

The relationships with $\tau$ are shown in the Figure below. Linear models of these predictors (except study grain due to NA's)


```{r warning = FALSE, message =FALSE}

## Calculating summary statistics for each trait/study/cell
bt_with_traits %>% 
  group_by(STUDY_ID_CELL) %>%
  summarise(SpDiversity = n_distinct( TidyBTName ),
            N_Years = n_distinct( YEAR ),
            YearRange = diff(range( YEAR ))) %>%
  ungroup() -> Assemblage_Stats          ## NB contains cells and species that are later cut out


StudyCell_level_TC %>%
  gather( Trait, Completeness, contains('Comp_')) %>%
  filter( Completeness > 0.4) %>%
  mutate( Trait = str_remove(Trait, 'Comp_')) %>%
  select( STUDY_ID_CELL , Completeness, Trait )  %>%
  separate(STUDY_ID_CELL , into = c('STUDY_ID', 'Cell' ), 
           remove = FALSE, convert = TRUE) %>%
  ungroup() %>%
  arrange( STUDY_ID)-> AssemblageTraitCompleteness



### Calculate average turnover in each assemblage and study

AllThree_All_cut %>%
  group_by(STUDY_ID_CELL ,  trait  ) %>% 
  summarise(Assem_MeanAbsRankChange = mean( MeanAbsRankChange) ) %>%
  separate(STUDY_ID_CELL , into = c('STUDY_ID', 'Cell' ), 
           remove = FALSE, convert = TRUE) %>%
  group_by(STUDY_ID ,  trait  ) %>%
  summarise(Study_MeanAbsRankChange= mean( Assem_MeanAbsRankChange) )-> Study_MeanAbsRankChange

 
# ### Trait Ranges

Winsorize <- function (x, probs = c(0.05, 0.95)) { ## DescTools::Winsorize
  xq <- quantile(x = x, probs = probs, na.rm = TRUE, type = 7)
  minval <- xq[1L]
  maxval <- xq[2L]
  x[x < minval] <- minval
  x[x > maxval] <- maxval
  return(x)
}


AllThree_All_cut3%>% 
  group_by(STUDY_ID_CELL, trait ) %>%
  mutate(TrimmedTrait_value = Winsorize(trait_value) )%>%
  summarise( MIN= min(trait_value , na.rm=TRUE),
             MAX = max(trait_value, na.rm=TRUE),
             MIN_trim= min(TrimmedTrait_value , na.rm=TRUE),
             MAX_trim = max(TrimmedTrait_value, na.rm=TRUE))%>%
  mutate( OrdersOfMag_Range = ifelse(  trait         ==   'TR_Mean_SeedMass',
                                       MAX-MIN, 
                                       log10(MAX) - log10(MIN)),
           OrdersOfMag_Range_trim = ifelse(  trait         ==   'TR_Mean_SeedMass',
                                       MAX_trim-MIN_trim, 
                                       log10(MAX_trim) - log10(MIN_trim)))%>%
  select( STUDY_ID_CELL, trait, OrdersOfMag_Range, OrdersOfMag_Range_trim ) -> TraitRanges


### Just take the assemblages that were actually used:
AllThree_All_cut %>%
  separate(STUDY_ID_CELL , into = c('STUDY_ID', 'Cell' ), remove = FALSE, convert = TRUE) %>%
  distinct(STUDY_ID, STUDY_ID_CELL, trait) %>%
  ungroup() %>%  
  rename(Trait = trait) %>%
  #filter( STUDY_ID_CELL  =='10_359170'           ) %>%
  left_join(AssemblageTraitCompleteness ,  by = c("STUDY_ID_CELL", "STUDY_ID", "Trait")) %>%
  left_join(Assemblage_Stats,  by = c("STUDY_ID_CELL"))%>%
  left_join(TraitRanges, by = c("STUDY_ID_CELL", 'Trait' = 'trait')) -> AllAssemblageLevelStats



AllAssemblageLevelStats %>%
  group_by(STUDY_ID, Trait ) %>%
  summarise( N_Cell = n_distinct(STUDY_ID_CELL) , 
             Mean_Sp_div = mean(SpDiversity ) ,
             Mean_N_Years = mean(N_Years),
             Mean_Completeness = mean(Completeness),
             Mean_TraitRange = mean(OrdersOfMag_Range),
             Mean_TraitRange_Trim = mean(OrdersOfMag_Range_trim),
             Mean_YearRange = mean(YearRange  )) %>%
  left_join(select(bt_meta,## Values direct from BioTIME metadata:
                   STUDY_ID  ,TITLE , REALM,  CLIMATE,PROTECTED_AREA ,
                   GRAIN_SQ_KM  ,ABUNDANCE_TYPE, 
                   BIOMASS_TYPE ,CENT_LAT ,CENT_LONG ),
            by = "STUDY_ID") %>%
  left_join( Study_MeanAbsRankChange,   
             by = c("STUDY_ID", 'Trait' = 'trait') )%>%
  ungroup()-> StudyExplanators



```

### Effect of trait range


```{r}
StudyExplanators %>%
  left_join( Three_Taus, by = c("STUDY_ID", 'Trait' = 'trait')) %>% 
    filter( Trait != 'TR_QualBS_Numeric' ) %>%
  ggplot( aes ( x = Mean_TraitRange, y =D19_Tau  ))+
  geom_point()+
  facet_grid(~Trait, scales = 'free_x')+
  ylab('Size-Trait - Popn Trend\nCorrelation') +
  xlab('Trait Range (Orders of magnitude)') +
  ggtitle( 'Un-Trimmed')+
  geom_hline(yintercept = 0)+
  coord_cartesian(xlim = c(0,NA))

StudyExplanators %>%
  left_join( Three_Taus, by = c("STUDY_ID", 'Trait' = 'trait')) %>% 
  filter( Trait != 'TR_QualBS_Numeric' ) %>%
  ggplot( aes ( x = Mean_TraitRange_Trim, y =D19_Tau  ))+
  geom_point()+
  facet_grid(~Trait, scales = 'free_x')+
  ylab('Size-Trait - Popn Trend\nCorrelation') +
  xlab('Trait Range (Orders of magnitude)') +
  ggtitle( 'Trimmed (only central 90% kept)')+
  geom_hline(yintercept = 0)+
  coord_cartesian(xlim = c(0,NA))


### 'Trait Range' Range (Masses)
StudyExplanators %>%
  filter( Trait %in% c( "TR_adult_body_mass_g" ,"TR_Mean_SeedMass" )) %>% 
  summarise(mean(Mean_TraitRange), 
            median(Mean_TraitRange),
            min(Mean_TraitRange),
            max(Mean_TraitRange))

### 'Trait Range' Range (lengths/heights)
StudyExplanators %>%
  filter( Trait %in% c( "TR_BodyLength_mm", "TR_Mean_LengthMax" ,  "TR_Max_Height"))%>% 
  summarise(mean(Mean_TraitRange), 
            median(Mean_TraitRange),
            min(Mean_TraitRange),
            max(Mean_TraitRange))
```


```{r  warning = FALSE, message =FALSE}
StudyExplanators %>%
  mutate( LogCells = log10(N_Cell),
          GRAIN_SQ_KM_Log = log10(GRAIN_SQ_KM),
          Abs_Lat= abs(CENT_LAT)) %>% 
  select(STUDY_ID , Trait, 
         LogCells,
         Mean_Sp_div,
         Mean_N_Years,
         Mean_Completeness,
         Mean_TraitRange,
         #    Study_MeanAbsRankChange ,
         Mean_YearRange,
         PROTECTED_AREA,
         GRAIN_SQ_KM_Log,
         Abs_Lat) -> StudyExplanators4Stats

StudyExplanators4Stats %>%
  gather( 'predictor', 'value', LogCells  : Abs_Lat   ) %>% 
  left_join( Three_Taus, by = c("STUDY_ID", 'Trait' = 'trait')) %>% 
  select(  STUDY_ID ,Trait,  Study_Tau =  D19_Tau , predictor, value,) %>%
  mutate( Trait= recode(Trait , "TR_BodyLength_mm"="Marine:  Body Length",
                        "TR_QualBS_Numeric" = "Marine: Qualitative Body Size" ,
                        "TR_Mean_LengthMax"= "Fish: Maximum Length", 
                        "TR_adult_body_mass_g"= "Amniotes:Adult body mass",
                        "TR_Mean_SeedMass"="Plants: Seed Mass",
                        "TR_Max_Height"="Plants: Maximum Height"  )) %>%
  mutate( predictor = recode(predictor ,
                             'CENT_LAT' =  'Latitude',
                             'GRAIN_SQ_KM_Log' = 'Sampling Grain\n(log10)',
                             'Mean_YearRange' = 'Year Range',
                             "Mean_Completeness"='Trait Completeness',
                             "Mean_N_Years" =   'Years Sampled' ,
                             #  'Study_MeanAbsRankChange' = 'Average Rank Change', 
                             'Mean_TraitRange' = 'Trait Range\n(Orders of Magnitude)',
                             "Mean_Sp_div"= 'Species Richness',
                             'Abs_Lat' = 'Absolute Latitude' ,
                             "LogCells"= 'Number of Cells\n(log10)',
                             "PROTECTED_AREA"="Protected Area"  )) -> TauPredictorsPlotData
  
PlotA <- c('Sampling Grain\n(log10)','Year Range',
           'Trait Completeness','Years Sampled')

PlotB <- c(  'Trait Range\n(Orders of Magnitude)',
             'Species Richness', 'Absolute Latitude' ,
             'Number of Cells\n(log10)', "Protected Area")


 TauPredictorsPlotData %>% 
  filter( predictor %in% PlotA) %>% 
  ggplot(aes(value,Study_Tau))+
  geom_point()+
  ylab('tau')+
  xlab('Predictor Value')+
   ggtitle('a)')+
  facet_grid(Trait~predictor ,scales = 'free') -> TauPredictorsPlotA

TauPredictorsPlotA


 TauPredictorsPlotData %>% 
  filter( predictor %in% PlotB) %>%
  ggplot(aes(value,Study_Tau))+
  geom_point()+
  ylab('tau')+
  xlab('Predictor Value')+
      ggtitle('b)')+
  facet_grid(Trait~predictor ,scales = 'free') -> TauPredictorsPlotB

TauPredictorsPlotB


ggsave('../Plots/TauPredictorsPlotA.png', TauPredictorsPlotA, width = 14, height =11)
ggsave('../Plots/TauPredictorsPlotB.png', TauPredictorsPlotB, width = 14, height =11)

```

### Fitting models

```{r}


StudyExplanators4Stats %>%
  left_join( select (Three_Taus, STUDY_ID, Trait = trait,Tau =  D19_Tau), by = c("STUDY_ID", "Trait")) %>%
  as.data.frame()-> Data_4_Predictions

# Full Raw results tables 

# NB A table of trait/study level results is available as 'Study_Corr_Predictors.csv'

Data_4_Predictions %>%
  write_csv('../Results/Study_Corr_Predictors.csv') ## for extended data. 

FF <- Tau~   LogCells+ Mean_Sp_div +Mean_N_Years +Mean_YearRange+ Mean_TraitRange + Abs_Lat+ Mean_Completeness   #+Study_MeanAbsRankChange

Pred_Labels <-  c('Intercept','Species Richness', 
                  'Number of Cells (Log 10)', 
                  'Years Sampled', 'Year Range', 'Trait Range', 
                  'Absolute Latitude' ,'Trait Completeness' #,  'Average Rank Change'
)


M1 <- lm(FF,   data = filter(Data_4_Predictions,  Trait == TraitNames[1], !is.na( Tau)) ) 
# M2 <- lm(FF,   data = filter(Data_4_Predictions,  Trait == TraitNames[2], !is.na( Tau)) ) ## not enough data points to get a meaningful estimate
M3 <- lm(FF,   data = filter(Data_4_Predictions,  Trait == TraitNames[3], !is.na( Tau)) ) 
M4 <- lm(FF,   data = filter(Data_4_Predictions,  Trait == TraitNames[4], !is.na( Tau)) ) 
M5 <- lm(FF,   data = filter(Data_4_Predictions,  Trait == TraitNames[5], !is.na( Tau)) ) 
M6 <- lm(FF,   data = filter(Data_4_Predictions,  Trait == TraitNames[6], !is.na( Tau)) ) 


TableS2<- sjPlot::tab_model(M1,  M3, M4, M5, M6, title = 'Predictors for τ with each trait',
                            pred.labels =Pred_Labels,
                            show.ci = FALSE, 
                            dv.labels  =TidyName[c(1,3:6)], digits = 4) 
TableS2

FF2 <- Tau^2~  LogCells+ Mean_Sp_div +Mean_N_Years +Mean_YearRange+  Mean_TraitRange +Abs_Lat+ Mean_Completeness   #+Study_MeanAbsRankChange


M1_2 <- lm(FF2,   data = filter(Data_4_Predictions,  Trait == TraitNames[1], !is.na( Tau)) ) 
#M2_2 <- lm(FF2,   data = filter(Data_4_Predictions,  Trait == TraitNames[2], !is.na( Tau)) ) 
M3_2 <- lm(FF2,   data = filter(Data_4_Predictions,  Trait == TraitNames[3], !is.na( Tau)) ) 
M4_2 <- lm(FF2,   data = filter(Data_4_Predictions,  Trait == TraitNames[4], !is.na( Tau)) ) 
M5_2 <- lm(FF2,   data = filter(Data_4_Predictions,  Trait == TraitNames[5], !is.na( Tau)) ) 
M6_2 <- lm(FF2,   data = filter(Data_4_Predictions,  Trait == TraitNames[6], !is.na( Tau)) ) 


TableS3<-sjPlot::tab_model(M1_2, M3_2, M4_2, M5_2, M6_2, title = 'Predictors for τ-squared with each trait',
                           pred.labels = Pred_Labels,
                           show.ci = FALSE, 
                           dv.labels  =TidyName[c(1,3:6)], digits = 4) 

TableS3

```

```{r warning = FALSE, message = FALSE, echo = FALSE}
## Building DF to use in extended data (sjPLOT doesn't work well with pdfs...)

N_Obs <- map_dbl(c(1,3,4,5,6),
                 function(i){nrow(filter(Data_4_Predictions,
                                         Trait == TraitNames[i],
                                         !is.na(Tau )))} )

N_Obs_vec <- c( 'Observations', N_Obs[1], '',N_Obs[2], '',N_Obs[3], '',N_Obs[4], '',N_Obs[5], '')


TableS2_df <- bind_cols(Pred_Labels,
                        signif(map_dfc( list(M1, M3, M4, M5, M6),
                                        function(M){select( tidy(M), estimate, p.value ) }),
                               3))

R2_adj =  map_dbl( list(M1, M3, M4, M5, M6),
                   function(M){summary(M)$adj.r.squared})%>%
  signif(3)

TableS2_R2_adj <- c( 'R2Adjust', R2_adj[1], '',R2_adj[2], '',R2_adj[3], '',R2_adj[4], '',R2_adj[5], '')

TableS2_dirty<- rbind(TableS2_df,
                      N_Obs_vec,
                      TableS2_R2_adj)


save(TableS2_dirty, file = '../SIdata/TableS2_dirty')



TableS3_df <- bind_cols(Pred_Labels,
                        signif(map_dfc( list(M1_2, M3_2, M4_2, M5_2, M6_2),
                                        function(M){select( tidy(M), estimate, p.value ) }),
                               3))

R2_adj =  map_dbl( list(M1_2, M3_2, M4_2, M5_2, M6_2),
                   function(M){summary(M)$adj.r.squared})%>%
  signif(3)

TableS3_R2_adj <- c( 'R2Adjust', R2_adj[1], '',R2_adj[2], '',R2_adj[3], '',R2_adj[4], '',R2_adj[5], '')

TableS3_dirty<- rbind(TableS3_df,
                      N_Obs_vec,
                      TableS3_R2_adj)

save(TableS3_dirty, file = '../SIdata/TableS3_dirty')

```

# Global distribution map (Figure 1)

```{r}
library(maps)

world_map<-map_data("world")
```


```{r echo = FALSE}
### Map with overlapping symbols (not used)

StudyExplanators %>%
  left_join( Three_Taus, by = c("STUDY_ID", 'Trait' = 'trait')) %>%
  select(STUDY_ID , Trait, Tau = D19_Tau,CENT_LAT , CENT_LONG  ,REALM  ) %>%
  left_join(data.frame( Trait = c("TR_BodyLength_mm",
                                  "TR_Mean_LengthMax",
                                  "TR_QualBS_Numeric",
                                  "TR_adult_body_mass_g",
                                  "TR_Mean_SeedMass",
                                  "TR_Max_Height" ),
                        shape = c('▲','■','♦','●','+','♣')), 
            by = "Trait")%>%
  mutate(Biome =  ifelse( REALM == 'Terrestrial', 
                          'Terrestrial', 'Aquatic')) %>%
  filter( !is.nan(Tau)) -> Data4Map

ggplot()+
  coord_fixed()+
  xlab("")+ylab("")+
  geom_polygon(data=world_map, size=0,
               aes(x=long, y=lat, group=group), 
               colour="white", fill="black")+
  theme(panel.grid.major=element_blank(),
        panel.grid.minor=element_blank(), 
        panel.background=element_rect(fill="white", colour="white"), 
        axis.line=element_line(colour="white"),	
        axis.ticks=element_blank(),
        axis.text.x=element_blank(), 
        axis.text.y=element_blank())+
  geom_point(data=  Data4Map,
             aes(x=CENT_LONG, y=CENT_LAT, col = Tau , shape = Trait))+
  scale_colour_gradientn(colours = c('blue4','blue3', 'blue1', 'yellow','red1','red3', 'red4') ,
                         limits = c(-0.5, 0.5), 
                         name = 'Mean Correlation')+
  scale_shape(solid = FALSE,
              breaks =  c("TR_BodyLength_mm",
                          "TR_Mean_LengthMax",
                          "TR_QualBS_Numeric",
                          "TR_adult_body_mass_g",
                          "TR_Mean_SeedMass",
                          "TR_Max_Height" ),
              name = 'Group:Trait',
              labels = c("TR_BodyLength_mm"="Marine:  Body Length",
                         "TR_QualBS_Numeric" = "Marine: Qualitative Body Size" ,
                         "TR_Mean_LengthMax"= "Fish: Maximum Length", 
                         "TR_adult_body_mass_g"= "Amniotes:Adult body mass",
                         "TR_Mean_SeedMass"="Plants: Seed Mass",
                         "TR_Max_Height"="Plants: Maximum Height"  ))+
  theme(legend.position = 'bottom') +
  guides(colour = guide_colourbar(title.position="top", title.hjust = 0.5),
         shape = guide_legend(title.position="top", title.hjust = 0.5, ncol = 2)) -> Map1
```


```{r}
## Map 2 Using repelling symbols

ggplot()+
  coord_fixed(xlim = c(-170, 170),
              ylim = c(-65, 80) )+
  xlab("")+ylab("")+
  geom_polygon(data=world_map, size=0,
               aes(x=long, y=lat, group=group), 
               colour=FALSE, fill="black")+
  theme(panel.grid.major=element_blank(),
        panel.grid.minor=element_blank(), 
        panel.background=element_rect(fill="grey90", colour="white"), 
        axis.line=element_line(colour="white"),	
        axis.ticks=element_blank(),
        axis.text.x=element_blank(), 
        axis.text.y=element_blank()
  )+
  geom_text_repel(data=  Data4Map,seed = 1, size = 4,
                  max.iter = 5000,segment.size = 0.3,
                  arrow =  arrow(length = unit(0.005, "npc")),
                  aes(x=CENT_LONG, y=CENT_LAT,
                      col = Tau, label = shape), )+
  scale_colour_gradientn(colours = c('blue4','blue3', 'blue1', 'yellow','red1','red3', 'red4') ,
                         limits = c(-0.7, 0.7), 
                         name = 'Population Change : Size Trait Rank\nCorrelation (τ)')+
  theme(legend.position=c(0.1,0.1),
        legend.margin = margin(10, 20, 10, 20),
        #   legend.key.size = unit(0.2, "cm"),
        legend.direction = "horizontal", legend.title.align = 0.5) +
  guides(colour = guide_colourbar(title.position="top",
                                  barwidth = 10))  ->   Map2


ggsave( '../Plots/SingleMap2.png',plot = Map2, width = 13, height = 6)                     
ggsave( '../Plots/SingleMap2.pdf',plot = Map2, width = 13, height = 6, device = cairo_pdf)                     



```


### Map splitting by wet/dry

```{r  warning = FALSE, message =FALSE}

Dry_data<- filter( Data4Map, Biome =='Terrestrial')
Wet_Data <-  filter( Data4Map, Biome =='Aquatic')

ggplot()+
  coord_fixed(xlim = c(-170, 170),
              ylim = c(-65, 80) )+
  xlab("")+ylab("")+
  geom_polygon(data=world_map, size=0,
               aes(x=long, y=lat, group=group), 
               colour=FALSE, fill="black")+
  theme(panel.grid.major=element_blank(),
        panel.grid.minor=element_blank(), 
        panel.background=element_rect(fill="grey70", colour="white"), 
        axis.line=element_line(colour="white"),	
        axis.ticks=element_blank(),
        axis.text.x=element_blank(), 
        axis.text.y=element_blank()
  )+
  geom_text_repel(data=  Dry_data,seed = 2, size = 4,
                  max.iter = 2000,segment.size = 0.3, box.padding = 0.1,
                  min.segment.length=0.01,
                  arrow =  arrow(length = unit(0.005, "npc")),
                  aes(x=CENT_LONG, y=CENT_LAT,
                      col = Tau, label = shape), )+
  scale_colour_gradientn(colours = c('blue4','blue3', 'blue1', 'white','red1','red3', 'red4') ,
                         limits = c(-0.7, 0.7))+
  guides(colour = FALSE)  ->   DryMap


ggplot()+
  coord_fixed(xlim = c(-170, 170),
              ylim = c(-65, 80) )+
  xlab("")+ylab("")+
  geom_polygon(data=world_map, size=0,
               aes(x=long, y=lat, group=group), 
               colour=FALSE, fill="black")+
  theme(panel.grid.major=element_blank(),
        panel.grid.minor=element_blank(), 
        panel.background=element_rect(fill="grey70", colour="white"), 
        axis.line=element_line(colour="white"),	
        axis.ticks=element_blank(),
        axis.text.x=element_blank(), 
        axis.text.y=element_blank()
  )+
  geom_text_repel(data=  Wet_Data,seed = 2, size = 4,
                  max.iter = 2000,segment.size = 0.3, box.padding = 0.1,
                  min.segment.length=0.01,
                  arrow =  arrow(length = unit(0.005, "npc")),
                  aes(x=CENT_LONG, y=CENT_LAT,
                      col = Tau, label = shape), )+
  scale_colour_gradientn(colours = c('blue4','blue3', 'blue1', 'white','red1','red3', 'red4') ,
                         limits = c(-0.7, 0.7), 
                         name = 'Population Change : Size Trait Rank\nCorrelation (τ)')+
  theme(legend.margin = margin(10, 20, 10, 20),
        #   legend.key.size = unit(0.2, "cm"),
        legend.direction = "horizontal", legend.title.align = 0.5) +
  guides(colour = guide_colourbar(title.position="top",
                                  barwidth = 10))  ->   WetMap



symbols<-data.frame(  shape = c('▲','■','♦','●','+','♣'),
                      Trait = c('Marine:  Body length' ,
                                'Marine: Qualitative body size',
                                'Fish: Maximum length',
                                'Amniotes: Adult body mass',
                                'Plants: Seed mass', 
                                'Plants: Maximum height'))

ShapeLeg  <- data.frame(  text= paste(symbols$shape, '  ',symbols$Trait), 
                          x = c(0,0,0,0,0,0),
                          y = c(6:1)) %>%
  ggplot( aes(x,y, label = text  ))+
  geom_text(size = 3, hjust  = 'left')+
  theme_nothing()+
  coord_cartesian(xlim = c( -1,10 ), ylim = c( 0,7))


Combn_Legend<- plot_grid(get_legend(WetMap), ShapeLeg, rel_widths = c(2,1))

Map3<- plot_grid( DryMap+ggtitle('a) Terrestrial' ),
                  WetMap +guides(col =FALSE)+ggtitle('b) Aquatic'), 
                  Combn_Legend, ncol = 1, rel_heights = c(3,3,0.75))

#Map3


ggsave( '../Plots/SplitMap3.png',plot = Map3, width = 7, height = 7, dpi = 300)                     
ggsave( '../Plots/SplitMap3.pdf',plot = Map3, width = 7, height = 7, device = cairo_pdf)                     

```


# Summary statistics

Calculation of statistics covering the scope of the final data used. NB, before the new tighter filtering procedure:
 *22,915  community time series from 167 studies, representing 2,516,175 observations of 12,033 species, of which 8,238 could be linked to at least one ‘size’ trait (representing 84.6% of observations). Equally weighting studies, the average time series length was 17.2 years (range 5-70.5) and the average number of species per included assemblage was 56.7 (range 10-337)*


## Number of studies/species/time/observations

```{r}
## Number of assemblages and studies used

AllThree_All_cut %>% ungroup %>%
  summarise(   n_distinct(STUDY_ID_CELL) ,
               n_distinct(STUDY_ID) )  

## Realms

## n observations used & percent observations with traits

AllThree_All_cut %>%
  distinct(   STUDY_ID_CELL , STUDY_ID ) %>%   ## study cells used (only once per trait)
  left_join(bt_with_traits,
            by = c("STUDY_ID_CELL", "STUDY_ID")) %>%
  ungroup()%>%
  summarise( n(), mean(HasTraits)*100, n_distinct( TidyBTName )) %>%
  kable

#####################>>>> FROM HERE 


## number of species with trait data
AllThree_All_cut %>%
  distinct(   STUDY_ID_CELL , STUDY_ID ) %>% 
  left_join(bt_with_traits,
            by = c("STUDY_ID_CELL", "STUDY_ID")) %>%
    ungroup() %>%
  distinct( TidyBTName , HasTraits) %>%
  ungroup() %>%
  count(HasTraits)


## Average length of studies
hist(StudyExplanators4Stats$Mean_YearRange)
mean(StudyExplanators4Stats$Mean_YearRange)
range(StudyExplanators4Stats$Mean_YearRange)

## Average number of species
hist(StudyExplanators4Stats$Mean_Sp_div)
mean(StudyExplanators4Stats$Mean_Sp_div)
range(StudyExplanators4Stats$Mean_Sp_div)


```



\newpage

# Trait Coverage statistics

Note that the final data used is less than this, since some studies are excluded due to insufficient study-level trait coverage. 

At *observation* level:
```{r}
bt_with_traits %>%
  mutate( HAS_AdultBodyMass   =!is.na(TR_adult_body_mass_g ),
          HAS_SeedMass        =!is.na(TR_Mean_SeedMass),
          HAS_VegetativeHeight=!is.na(TR_Max_Height),
          HAS_WoRMSBodyLength =!is.na(TR_BodyLength_mm),
          HAS_QualSize        =!is.na(TR_QualitativeBodySize),
          HAS_FishMaxLength   =!is.na(TR_Mean_LengthMax )) -> HasTRAITSdata


HasTRAITSdata %>%
  summarise(sum( HAS_AdultBodyMass), 
            sum(   HAS_SeedMass  ), 
            sum(         HAS_VegetativeHeight), 
            sum(   HAS_WoRMSBodyLength ), 
            sum(   HAS_QualSize      ), 
            sum(     HAS_FishMaxLength   )) %>% 
  t %>% kable

HasTRAITSdata %>%
  count(HAS_AdultBodyMass,HAS_SeedMass ,HAS_VegetativeHeight,HAS_WoRMSBodyLength,
        HAS_QualSize,HAS_FishMaxLength, sort = TRUE ) 

```

At *species* level:

```{r}

HasTRAITSdata %>%
  distinct(TidyBTName, HAS_AdultBodyMass,HAS_SeedMass, HAS_VegetativeHeight,
           HAS_WoRMSBodyLength,  HAS_QualSize   ,  HAS_FishMaxLength  ) %>%
  summarise(sum(HAS_AdultBodyMass), 
            sum(HAS_SeedMass  ), 
            sum(HAS_VegetativeHeight), 
            sum(HAS_WoRMSBodyLength ), 
            sum(HAS_QualSize      ), 
            sum(HAS_FishMaxLength   )) %>% 
  t %>% kable
```


## Trait data overlap 

There is little overlap between the trait databases as they cover rather different taxa. The principal (unsurprising) exception is that a large proportion of the entries in the fish database are shared with the WoRMS database. NB that it is species that are counted here, not observations. Within the WoRMS database few species have both quantitative and qualitative body size data. The overlap within the plant database was much higher. Although the overall correlation between the two plant trait values is strong, there are two clear clusters of height, within which the correlation between seed size and plant height is weaker. Since the BioTIME studies tend to focus on particular guilds, this justifies the use of both traits. Where there is data from both the more general 'marine' database (WoRMS) and the specialised fish database, the two values closely correlate. 

```{r}
x <- list( HAS_SeedMassOrVegHeight    =  unique(pull(filter(HasTRAITSdata,HAS_SeedMass| HAS_VegetativeHeight), TidyBTName )),
           HAS_AdultBodyMass          =  unique(pull(filter(HasTRAITSdata,HAS_AdultBodyMass                 ), TidyBTName )),
           HAS_WoRMSBodyLengthOrQualL =  unique(pull(filter(HasTRAITSdata,HAS_WoRMSBodyLength |HAS_QualSize ), TidyBTName )),
           HAS_FishMaxLength          =  unique(pull(filter(HasTRAITSdata,HAS_FishMaxLength                ), TidyBTName )))


TraitDBVenn_sp<-ggVennDiagram(x, 
                              category.names = c( 'TRY\n(Seed mass\nor Height))',
                                                  'Amniote (Body Mass)',
                                                  'WoRMS\n(Qualitative\nor Quantitative)', 
                                                  'Fish  (Length)')) +
  guides(fill = FALSE)+
  scale_fill_gradient(high = "grey50", low = "white")
TraitDBVenn_sp

WoRMSOverlap <- list(HAS_WoRMSBodyLength =  unique(pull(filter(HasTRAITSdata,HAS_WoRMSBodyLength), TidyBTName )),
                     HAS_WoRMSQualL =  unique(pull(filter(HasTRAITSdata,HAS_QualSize), TidyBTName )))

WoRMS_Venn <- ggVennDiagram(WoRMSOverlap, category.names = c( 'Quantitative\nBody Length', 
                                                              'Qualitative\nBody Size'))+
  guides(fill = FALSE)+
  scale_fill_gradient(high = "grey50", low = "grey80")
WoRMS_Venn


TRYOverlap <- list(HAS_SeedMass=  unique(pull(filter(HasTRAITSdata,HAS_SeedMass), TidyBTName )),
                   HAS_VegHeight =  unique(pull(filter(HasTRAITSdata,HAS_VegetativeHeight), TidyBTName )))


TRY_Venn <- ggVennDiagram(TRYOverlap, category.names = c( 'Seed Mass', 
                                                          'Vegetative\nHeight'))+
  guides(fill = FALSE)+
  scale_fill_gradient(high = "grey50", low = "grey80")


TRY_Venn
```


```{r}
QualQuant <- HasTRAITSdata %>%  
  filter(HAS_WoRMSBodyLength , HAS_QualSize   ) %>%
  distinct(TidyBTName , TR_BodyLength_mm ,  TR_QualBS_Numeric)

  cor(QualQuant$TR_BodyLength_mm, QualQuant$TR_QualBS_Numeric, method = 'spearman')

```

```{r}


PlantCorrPlot<- HasTRAITSdata %>%#
  filter(HAS_SeedMass,  HAS_VegetativeHeight) %>%
  distinct(TidyBTName , TR_Mean_SeedMass,  TR_Max_Height)%>%
  ggplot(aes(TR_Mean_SeedMass , TR_Max_Height ) ) +
  geom_point()+
  scale_y_log10() +
  theme_classic()+
  xlab( 'Seed Mass')+#
  ylab( 'Maximum Vegetative Height')
PlantCorrPlot
```



```{r}
### Fish lengths

FishCorrPlot<- HasTRAITSdata %>%#
  filter(HAS_WoRMSBodyLength,  HAS_FishMaxLength) %>%
  distinct(TidyBTName , TR_BodyLength_mm ,  TR_Mean_LengthMax )%>%
  ggplot(aes(x= TR_BodyLength_mm  , y= TR_Mean_LengthMax  ) ) +
  geom_point()+
  theme_classic()+
  xlab( 'WoRMS Length')+
  ylab( 'Fishbase Length')+
  scale_x_log10()+
  scale_y_log10() 
FishCorrPlot
```


```{r}
plot_grid(TraitDBVenn_sp + ggtitle('a)'), 
          plot_grid( WoRMS_Venn+ ggtitle('b)'),
                     FishCorrPlot+ ggtitle('c)'),
                     TRY_Venn+ ggtitle('d)') ,
                     PlantCorrPlot+ ggtitle('e)'), nrow = 2),
          ncol = 1, rel_heights = c(1, 1.5))-> ExtDatFig2
ggsave( '../Plots/TraitOverlapPlot.pdf',ExtDatFig2, height = 12, width = 9)

```


##  Studies with multiple traits

```{r}
StudyExplanators4Stats %>% 
  select( STUDY_ID, Trait) %>%
  add_count(STUDY_ID) %>%
  filter( n>1) %>%
  arrange(STUDY_ID,  Trait) %>%
  group_by(STUDY_ID) %>%
  summarise( Pairs = paste(Trait, collapse = ' ' )) %>%
  count(Pairs)

```

```{r}
### Which studies from TRY actually used (and so need separate citing)

bt_with_traits%>%
  distinct(TRY_datasetIDs_Height ,TRY_datasetIDs_SeedMass ) %>%
  filter( !is.na(TRY_datasetIDs_Height ) |!is.na(TRY_datasetIDs_SeedMass )  ) -> TRY_studylist


(c(TRY_studylist$TRY_datasetIDs_SeedMass , TRY_studylist$TRY_datasetIDs_Height)%>%
    paste(collapse = ' ') %>%
    str_split(pattern = ' '))[[1]] %>%
  as.numeric() %>%
  na.omit() %>%
  unique() -> UniqueTryStudiesUsed

TRY_StudyRefs         <- read_csv('../TraitTables/TRY_StudyRefs_focal.csv')

TRY_StudyRefs %>%
  filter( DatasetID %in% UniqueTryStudiesUsed) %>%
  arrange(LastName)%>%
  distinct(Reference) %>% 
  write_csv('../TraitTables/RefsUsedFromTry.csv')


```


\newpage

# Supplementary Analysis: Assessment of winners and losers 

```{r warning = FALSE, message = FALSE}

AllThree_All_cut %>%
  filter(N_times_observed    >= 5  ) %>%
  mutate( WinLoss = ifelse( D19_pvalue >0.1 |D19_slope ==0 , 'No Clear Trend',  
                            ifelse(D19_slope >0,     'Winner', 'Loser'   ))) %>%
  separate(STUDY_ID_CELL , into = c('STUDY_ID', 'Cell' ), convert = TRUE) %>%
  select( STUDY_ID, Cell,TidyBTName  ,WinLoss, RelTraitRank , trait  ) %>%
  mutate(Trait_bin = ntile(RelTraitRank ,n = 20)) %>%
  group_by(STUDY_ID ,trait  ) %>%
  add_count(TidyBTName, name = 'N_AssemblagesIn') %>%
  mutate( weight = 1/N_AssemblagesIn) -> WinLossAll


write_csv(WinLossAll, '../SIdata/WinLossAll.csv')  #### Visualised in extended data 

WinLossAll %>%
  group_by(Trait_bin, trait) %>%
  count(WinLoss, wt = weight, name = 'WeightedCount'  ) %>%
  mutate( trait = recode(trait , "TR_BodyLength_mm"="Marine:  Body Length",
                         "TR_QualBS_Numeric" = "Marine: Qualitative Body Size" ,
                         "TR_Mean_LengthMax"= "Fish: Maximum Length", 
                         "TR_adult_body_mass_g"= "Amniotes: Adult body mass",
                         "TR_Mean_SeedMass"="Plants: Seed Mass",
                         "TR_Max_Height"="Plants: Maximum Height"  )) %>%
  ggplot( aes( Trait_bin, y= WeightedCount,fill = WinLoss))+
  geom_bar(stat = 'identity', position="fill")+
  facet_wrap(~trait, scales = 'free_y')+
  theme( panel.background = element_blank(),
         axis.text.x = element_blank() ,
         legend.position = 'bottom')+
  xlab('Within-assemblage relative trait values') +
  ylab('Frequency within\neach trait bin')+
  scale_fill_manual(values = c('red', 'grey', 'darkgreen'), name = 'Category') -> SpeciesLevelPlots

ggsave( '../Plots/SpeciesLevelPlots.png' ,SpeciesLevelPlots, width = 8, height =6, dpi = 300)
ggsave( '../Plots/SpeciesLevelPlots.pdf' ,SpeciesLevelPlots, width = 8, height =6)


WinnerStats<- map_df( TraitNames, function(t){
  WinLossAll %>%
    filter( trait == t) %>%
    mutate( Winner = WinLoss == 'Winner') %>%
    glm(data =  ., Winner  ~    RelTraitRank , weights = weight, family = 'binomial') %>%
    tidy %>%
    filter(term == 'RelTraitRank')%>%
    mutate( Trait = t,
            Response = 'ChanceOfWinner')
})


LoserStats<- map_df( TraitNames, function(t){
  WinLossAll %>%
    filter( trait == t) %>%
    mutate( Loser = WinLoss == 'Loser') %>%
    glm(data =  ., Loser  ~    RelTraitRank , weights = weight, family = 'binomial') %>%
    tidy %>%
    filter(term == 'RelTraitRank') %>%
    mutate( Trait = t,
            Response = 'ChanceOfLoser')
  
})


LogRegStats<- bind_rows(WinnerStats,LoserStats)
write_csv(LogRegStats, '../SIdata/LogRegStats.csv' )  #### Visualised in extended data 



LogRegStats %>%
  mutate( Trait = recode(Trait , "TR_BodyLength_mm"="Marine:  Body Length",
                         "TR_QualBS_Numeric" = "Marine: Qualitative Body Size" ,
                         "TR_Mean_LengthMax"= "Fish: Maximum Length", 
                         "TR_adult_body_mass_g"= "Amniotes: Adult body mass",
                         "TR_Mean_SeedMass"="Plants: Seed Mass",
                         "TR_Max_Height"="Plants: Maximum Height"  )) %>%
  select( - term) %>%
  select( Trait,  `Coefficent estimate` = estimate, SE = std.error, p.value ) %>%
  kbl(digits = 3, align = 'lccc') %>%
  pack_rows("Winners", 1,6) %>%
  pack_rows("Losers", 7,12)

WinLossAll %>%
  ungroup %>%
  count(trait, WinLoss, wt = weight) %>%
  spread(WinLoss, n) %>%
  mutate( trait = recode(trait , "TR_BodyLength_mm"="Marine:  Body Length",
                         "TR_QualBS_Numeric" = "Marine: Qualitative Body Size" ,
                         "TR_Mean_LengthMax"= "Fish: Maximum Length", 
                         "TR_adult_body_mass_g"= "Amniotes: Adult body mass",
                         "TR_Mean_SeedMass"="Plants: Seed Mass",
                         "TR_Max_Height"="Plants: Maximum Height"  )) %>%
  kable(digits = 4)

```




